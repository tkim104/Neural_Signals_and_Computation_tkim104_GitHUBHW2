{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 2: Dimensionality reduction\n",
        "Consider a dataset where M neurons are recorded during repeated trials of a reach task. The resulting data is a number of matrices (one per trial) that is N Ã—T (number of neurons by time - in 1 ms bins) where Xit represents the number of spikes for neuron i during the time-bin t. This problem will consider the dimensionality reduction approach of finding the underlying patterns of neural activity common across trials. Specifically we will first look at standard PCA before and after processing (to highlight the benefit of priors over spike-rates). We will then look at applying an external package that finds smooth spike-rates underlying the neural activity automatically (Gaussian Process Factor Analysis).\n",
        "\n",
        "##Part C\n",
        "Look in the GPFA folder. Identify how to run GPFA by looking at the demo files\n",
        "included. Run GPFA on the data with a bin-size of 1ms (instead of the default 20ms). GPFA returs per-trial representations of neural activity. Use the function provided in the gpfa code directory plot3D to plot the time-courses for all of the trials. What do you notice?"
      ],
      "metadata": {
        "id": "7Elc8fUXW_VA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "qhNkNIHRW9RQ",
        "outputId": "bbbbd235-d09b-4db3-8041-fc2f7e5ec711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: elephant in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: neo>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from elephant) (0.13.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from elephant) (1.25.2)\n",
            "Requirement already satisfied: quantities>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from elephant) (0.15.0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from elephant) (1.11.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from elephant) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from elephant) (4.66.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from neo>=0.10.0->elephant) (24.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Observation covariance matrix is rank deficient.\nPossible causes: repeated units, not enough observations.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-1026bb9710ff>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mgpfa_2dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPFA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dimensionality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mgpfa_2dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_psth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mtrajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpfa_2dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_psth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elephant/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         }\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/elephant/gpfa/gpfa.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, spiketrains)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;34m\"repeated units, not enough observations.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 )\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmesg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Observation covariance matrix is rank deficient.\nPossible causes: repeated units, not enough observations."
          ]
        }
      ],
      "source": [
        "!pip install elephant\n",
        "\n",
        "from elephant.gpfa import GPFA\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import quantities as pq\n",
        "import neo\n",
        "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
        "import matplotlib.pyplot as plt\n",
        "from quantities import s\n",
        "from neo.core import SpikeTrain\n",
        "\n",
        "print(\"Unfortunately, I could not find the exact Gaussian Process Factor Analysis folder for the assignment.\")\n",
        "print(\"Thus, I attempted to use another external program named elephant, but was not able to properly get it to work in time.\")\n",
        "print(\"The sources can be found here: https://elephant.readthedocs.io/en/latest/tutorials/gpfa.html\")\n",
        "\n",
        "# Find the file in google drive\n",
        "drive.mount('/content/drive')\n",
        "file = \"/content/drive/MyDrive/Neural_Signals_and_Computation_HW2/sample_dat.mat\"\n",
        "\n",
        "import scipy.io as sio\n",
        "mat_contents = sio.loadmat(file)\n",
        "data_trials = mat_contents['dat'][0]\n",
        "\n",
        "## Make Perstimulus Time Histograms\n",
        "raw_psth = []\n",
        "bins = np.arange(0, 0.4 + 0.001, 0.001)\n",
        "for i in range(len(data_trials[0][1])):\n",
        "  total = []\n",
        "  for trials in data_trials:\n",
        "    # This is number of spikes for Neuron i at time bin n (1 msec bins)\n",
        "    n1 = []\n",
        "    for j in range(len(trials[1][i])):\n",
        "      if trials[1][0][j] * 0.001 != 0:\n",
        "        for k in range(trials[1][i][j]):\n",
        "          n1.append(0.001 * j)\n",
        "      elif j == 0 and trials[1][i][j] > 0:\n",
        "        for k in range(trials[1][i][j]):\n",
        "          n1.append(0.001 * j)\n",
        "    if total is not None:\n",
        "      total += n1\n",
        "    else:\n",
        "      total = n1\n",
        "\n",
        "  y = np.histogram(total, bins=bins)[0] / len(data_trials)\n",
        "  spike_train = SpikeTrain(list(set(y))*s, t_stop=0.4)\n",
        "  raw_psth.append(spike_train)\n",
        "raw_psth = [raw_psth]\n",
        "# Conduct Gaussian Process\n",
        "num_trials = 1\n",
        "timestep = 1 * pq.ms\n",
        "\n",
        "# specify fitting parameters\n",
        "bin_size = 1 * pq.ms\n",
        "latent_dimensionality = 3\n",
        "\n",
        "gpfa_2dim = GPFA(bin_size=bin_size, x_dim=latent_dimensionality)\n",
        "gpfa_2dim.fit(raw_psth)\n",
        "trajectories = gpfa_2dim.transform(raw_psth)"
      ]
    }
  ]
}